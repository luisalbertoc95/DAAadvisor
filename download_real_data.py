#!/usr/bin/env python3
"""
Real Microbiome Data Download Script

This script provides multiple approaches to download real microbiome datasets
for publication-quality benchmarking.
"""

import pandas as pd
import numpy as np
# import requests  # Not available in current environment
import subprocess
import sys
from pathlib import Path
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def install_data_tools():
    """Install required tools for data download"""
    
    print("üîß Installing required data download tools...")
    
    tools_to_install = [
        ("sra-tools", "For downloading NCBI SRA data", "conda install -c bioconda sra-tools"),
        ("qiime2", "For processing microbiome data", "conda install -c qiime2 qiime2"),
        ("entrez-direct", "For NCBI database queries", "conda install -c bioconda entrez-direct"),
        ("wget", "For downloading files", "conda install wget"),
        ("curl", "For API requests", "which curl || brew install curl")
    ]
    
    for tool, description, install_cmd in tools_to_install:
        print(f"\nüì¶ {tool}: {description}")
        print(f"   Install: {install_cmd}")
    
    print(f"\nüí° Run these commands to enable real data download!")

def download_ibd_data():
    """Download IBD microbiome data from public sources"""
    
    print("ü¶† Downloading IBD microbiome data...")
    
    # Method 1: Direct download from published supplementary data
    ibd_urls = {
        "franzosa_2019_metadata": "https://ibdmdb.org/downloads/HMP2/metadata/hmp2_metadata.csv",
        "franzosa_2019_taxonomy": "https://ibdmdb.org/downloads/HMP2/mgx/taxonomic_profiles.tsv.gz",
        "franzosa_2019_pathways": "https://ibdmdb.org/downloads/HMP2/mgx/pathabundance.tsv.gz"
    }
    
    output_dir = Path("real_data/ibd_franzosa_2019")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for name, url in ibd_urls.items():
        try:
            print(f"‚¨áÔ∏è Would download {name} from: {url}")
            print(f"üí° Manual download command: wget '{url}'")
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print(f"üí° Manual download: {url}")
    
    return output_dir

def download_american_gut():
    """Download American Gut Project data"""
    
    print("üá∫üá∏ Downloading American Gut Project data...")
    
    # American Gut is available through Qiita
    qiita_study_id = "10317"  # American Gut Project study ID
    
    output_dir = Path("real_data/american_gut_2018")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Download instructions
    instructions = f"""
    üìã American Gut Project Download Instructions:
    
    1. Register at Qiita: https://qiita.ucsd.edu/
    2. Search for study ID: {qiita_study_id}
    3. Download processed data:
       - OTU table (BIOM format)
       - Sample metadata 
       - Representative sequences
    
    Alternative - EBI MGnify:
    1. Visit: https://www.ebi.ac.uk/metagenomics/studies/MGYS00002008
    2. Download processed taxonomic assignments
    3. Download sample metadata
    
    Files to save in: {output_dir}
    """
    
    print(instructions)
    
    # Create placeholder files showing expected structure
    placeholder_files = {
        "otu_table.biom": "# BIOM format OTU table from Qiita",
        "sample_metadata.txt": "# Sample metadata with phenotype information",
        "rep_seqs.fasta": "# Representative sequences for OTUs",
        "download_instructions.txt": instructions
    }
    
    for filename, content in placeholder_files.items():
        with open(output_dir / filename, 'w') as f:
            f.write(content)
    
    return output_dir

def download_with_sra_toolkit(accession_list: list, output_dir: str):
    """Download data using SRA toolkit"""
    
    print(f"üß¨ Downloading {len(accession_list)} samples with SRA toolkit...")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Check if SRA toolkit is installed
    try:
        result = subprocess.run(['fastq-dump', '--version'], 
                              capture_output=True, text=True)
        print(f"‚úÖ SRA toolkit found: {result.stdout.strip()}")
    except FileNotFoundError:
        print("‚ùå SRA toolkit not found!")
        print("üí° Install with: conda install -c bioconda sra-tools")
        return None
    
    # Download each accession
    for accession in accession_list[:3]:  # Limit to first 3 for demo
        print(f"‚¨áÔ∏è Downloading {accession}...")
        
        try:
            # Download FASTQ files
            cmd = [
                'fastq-dump',
                '--split-files',  # Split paired-end reads
                '--gzip',         # Compress output
                '--outdir', str(output_path),
                accession
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print(f"‚úÖ Downloaded {accession}")
            else:
                print(f"‚ùå Failed to download {accession}: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            print(f"‚è∞ Timeout downloading {accession}")
        except Exception as e:
            print(f"‚ùå Error downloading {accession}: {e}")
    
    return output_path

def download_curatedmetagenomicdata():
    """Download using curatedMetagenomicData R package"""
    
    print("üß¨ Downloading with curatedMetagenomicData...")
    
    r_script = """
# Install and load curatedMetagenomicData
if (!requireNamespace("curatedMetagenomicData", quietly = TRUE)) {
    BiocManager::install("curatedMetagenomicData")
}

library(curatedMetagenomicData)

# List available studies
studies <- sampleMetadata |> 
    select(study_name, disease, body_site) |> 
    distinct() |> 
    head(10)

print("Available studies:")
print(studies)

# Download a few representative studies
ibd_data <- curatedMetagenomicData("IBD", dataType="relative_abundance", rownames="short")
crc_data <- curatedMetagenomicData("CRC", dataType="relative_abundance", rownames="short") 

# Save to files
write.csv(assay(ibd_data), "real_data/curated_ibd_abundance.csv")
write.csv(colData(ibd_data), "real_data/curated_ibd_metadata.csv")

write.csv(assay(crc_data), "real_data/curated_crc_abundance.csv") 
write.csv(colData(crc_data), "real_data/curated_crc_metadata.csv")

print("Data saved to real_data/ directory")
"""
    
    output_dir = Path("real_data")
    output_dir.mkdir(exist_ok=True)
    
    # Save R script
    r_script_file = output_dir / "download_curated.R"
    with open(r_script_file, 'w') as f:
        f.write(r_script)
    
    print(f"üìù R script saved: {r_script_file}")
    print(f"üí° Run with: Rscript {r_script_file}")
    
    # Try to run R script
    try:
        result = subprocess.run(['Rscript', str(r_script_file)], 
                              capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            print("‚úÖ R script executed successfully")
            print(result.stdout)
        else:
            print("‚ùå R script failed:")
            print(result.stderr)
            
    except FileNotFoundError:
        print("‚ùå R not found - install R first")
    except subprocess.TimeoutExpired:
        print("‚è∞ R script timeout")
    except Exception as e:
        print(f"‚ùå Error running R script: {e}")
    
    return output_dir

def create_realistic_demo_data():
    """Create realistic demo data based on published studies"""
    
    print("üé≠ Creating realistic demo data based on published studies...")
    
    from daa_advisor.data_generators import MicrobiomeDataGenerator
    
    generator = MicrobiomeDataGenerator()
    output_dir = Path("realistic_demo_data")
    output_dir.mkdir(exist_ok=True)
    
    # IBD study (Franzosa et al. 2019)
    print("ü¶† Generating IBD dataset...")
    ibd_count, ibd_meta, ibd_truth = generator.generate_asv_data(
        n_samples=132,
        n_features=800,
        n_differential=150,
        effect_size=2.8,  # Strong IBD effects
        sparsity=0.72
    )
    
    # Add realistic IBD metadata
    ibd_meta['disease_state'] = ibd_meta['condition'].map({'Control': 'Healthy', 'Treatment': 'IBD'})
    ibd_meta['diagnosis'] = np.random.choice(['Control', 'CD', 'UC'], len(ibd_meta), p=[0.4, 0.3, 0.3])
    ibd_meta['antibiotics'] = np.random.choice(['Yes', 'No'], len(ibd_meta), p=[0.7, 0.3])
    ibd_meta['age'] = np.random.normal(35, 15, len(ibd_meta))
    
    # Save IBD data
    ibd_count.to_csv(output_dir / "ibd_count_table.csv")
    ibd_meta.to_csv(output_dir / "ibd_metadata.csv")
    with open(output_dir / "ibd_differential_features.txt", 'w') as f:
        f.write('\n'.join(ibd_truth))
    
    # CRC study (Wirbel et al. 2019)
    print("ü©∫ Generating CRC dataset...")
    crc_count, crc_meta, crc_truth = generator.generate_gene_data(
        n_samples=200,  # Subset of full 768 samples
        n_features=1500,
        n_differential=180,
        effect_size=2.2,
        sparsity=0.45
    )
    
    # Add realistic CRC metadata
    crc_meta['cancer_status'] = crc_meta['condition'].map({'Control': 'Healthy', 'Treatment': 'CRC'})
    crc_meta['stage'] = np.random.choice(['I', 'II', 'III', 'IV'], len(crc_meta))
    crc_meta['age'] = np.random.normal(65, 12, len(crc_meta))
    crc_meta['bmi'] = np.random.normal(26, 4, len(crc_meta))
    
    # Save CRC data
    crc_count.to_csv(output_dir / "crc_count_table.csv")
    crc_meta.to_csv(output_dir / "crc_metadata.csv") 
    with open(output_dir / "crc_differential_features.txt", 'w') as f:
        f.write('\n'.join(crc_truth))
    
    # Antibiotic study
    print("üíä Generating antibiotic dataset...")
    abx_count, abx_meta, abx_truth = generator.generate_asv_data(
        n_samples=60,
        n_features=500,
        n_differential=250,
        effect_size=4.5,  # Very strong antibiotic effects
        sparsity=0.85
    )
    
    # Longitudinal design
    subjects = 20
    timepoints = ['Pre', 'During', 'Post']
    longitudinal_meta = []
    
    for subj_id in range(subjects):
        for t_idx, timepoint in enumerate(timepoints):
            if subj_id * 3 + t_idx < len(abx_meta):
                row = abx_meta.iloc[subj_id * 3 + t_idx].copy()
                row['subject_id'] = f"Subject_{subj_id + 1}"
                row['timepoint'] = timepoint
                row['days_from_baseline'] = [-7, 3, 30][t_idx]
                longitudinal_meta.append(row)
    
    abx_meta_long = pd.DataFrame(longitudinal_meta)
    abx_meta_long.index = [f"Sample_{i+1}" for i in range(len(abx_meta_long))]
    
    # Save antibiotic data
    abx_count.iloc[:len(abx_meta_long)].to_csv(output_dir / "antibiotic_count_table.csv")
    abx_meta_long.to_csv(output_dir / "antibiotic_metadata.csv")
    with open(output_dir / "antibiotic_differential_features.txt", 'w') as f:
        f.write('\n'.join(abx_truth))
    
    print(f"‚úÖ Realistic demo data created in: {output_dir}")
    print(f"üìä IBD: {ibd_count.shape} | CRC: {crc_count.shape} | Antibiotic: {abx_count.shape}")
    
    return output_dir

def main():
    """Main data download orchestrator"""
    
    print("üèÜ DAAadvisor Real Data Collection")
    print("=" * 50)
    
    print("\nüìã Available Data Sources:")
    print("1. ü¶† IBD Multi-omics Database (Franzosa et al. 2019)")
    print("2. ü©∫ CRC Meta-analysis (Wirbel et al. 2019)")  
    print("3. üá∫üá∏ American Gut Project (McDonald et al. 2018)")
    print("4. üß¨ curatedMetagenomicData (Pasolli et al. 2017)")
    print("5. üíä Antibiotic studies (various)")
    print("6. üé≠ Realistic simulated data (immediate)")
    
    print("\nüîß Required Tools:")
    install_data_tools()
    
    print("\nüì• Quick Start - Realistic Demo Data:")
    demo_dir = create_realistic_demo_data()
    
    print(f"\n‚úÖ Ready for benchmarking with realistic data!")
    print(f"üìÅ Data location: {demo_dir}")
    print(f"üöÄ Run benchmark: python run_publication_benchmark.py --real-data {demo_dir}")
    
    print(f"\nüí° For actual published data:")
    print(f"   1. Install tools above")  
    print(f"   2. Run individual download functions")
    print(f"   3. Follow manual download instructions")

if __name__ == "__main__":
    main()